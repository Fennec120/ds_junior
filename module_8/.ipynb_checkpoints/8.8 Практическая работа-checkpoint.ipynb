{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7ytv2GMjpGZ"
   },
   "source": [
    "# Логистическая регрессия. Практическая работа\n",
    "\n",
    "## Цель практической работы\n",
    "\n",
    "Вы уже делали задание, в котором с помощью метода ближайших соседей оценивали склонность клиента банка откликнуться или не откликнуться на предложение.\n",
    "\n",
    "В этом практическом задании ваши цели:\n",
    "*  решить эту же задачу с помощью логистической регрессии;\n",
    "*  потренироваться в подборе порога; \n",
    "*  потренироваться в подборе гиперпараметров модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sj3n0n38nEfs"
   },
   "source": [
    "## Что входит в работу\n",
    "\n",
    "*  Загрузить данные для задачи.\n",
    "*  Обучить метод ближайших соседей с заданным количеством соседей k, вычислить метрики.\n",
    "*  Обучить логистическую регрессию с параметрами по умолчанию, вычислить метрики.\n",
    "*  Подобрать порог модели, вычислить метрики.\n",
    "*  Подобрать гиперпараметр С (константа регуляризации) модели, вычислить метрики."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3qfZPYNpoFGE"
   },
   "source": [
    "## Что оценивается\n",
    "\n",
    "*  Выполнены все этапы задания: код запускается, отрабатывает без ошибок; подробно и обоснованно написаны текстовые выводы, где это требуется."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3_EzM8UJoRHd"
   },
   "source": [
    "## Формат сдачи\n",
    "Выполните предложенные задания — впишите свой код (или, если требуется, текст) в ячейки после комментариев. \n",
    "\n",
    "*Комментарии — это текст, который начинается с символа #. Например: # ваш код здесь.*\n",
    "\n",
    "Сохраните изменения, используя опцию Save and Checkpoint из вкладки меню File или кнопку Save and Checkpoint на панели инструментов. Итоговый файл в формате .ipynb (файл Jupyter Notebook) загрузите в личный кабинет и отправьте на проверку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "aPDB2wP8jndz"
   },
   "outputs": [],
   "source": [
    "# подключим библиотеки\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stst'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst = 'stst'\n",
    "tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7Zw7RmtAjn8O"
   },
   "outputs": [],
   "source": [
    "# считаем данные\n",
    "df = pd.read_csv('8.8 ClientsData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "3QbRGWqJjxOv"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SOCSTATUS_WORK_FL</th>\n",
       "      <th>SOCSTATUS_PENS_FL</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>CHILD_TOTAL</th>\n",
       "      <th>DEPENDANTS</th>\n",
       "      <th>PERSONAL_INCOME</th>\n",
       "      <th>LOAN_NUM_TOTAL</th>\n",
       "      <th>LOAN_NUM_CLOSED</th>\n",
       "      <th>LOAN_DLQ_NUM</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGE  SOCSTATUS_WORK_FL  SOCSTATUS_PENS_FL  GENDER  CHILD_TOTAL  DEPENDANTS  \\\n",
       "0   49                  1                  0       1            2           1   \n",
       "1   32                  1                  0       1            3           3   \n",
       "2   52                  1                  0       1            4           0   \n",
       "3   39                  1                  0       1            1           1   \n",
       "4   30                  1                  0       0            0           0   \n",
       "\n",
       "   PERSONAL_INCOME  LOAN_NUM_TOTAL  LOAN_NUM_CLOSED  LOAN_DLQ_NUM  TARGET  \n",
       "0           5000.0               1                1             2       0  \n",
       "1          12000.0               1                1             1       0  \n",
       "2           9000.0               2                1             0       0  \n",
       "3          25000.0               1                1             3       0  \n",
       "4          12000.0               2                1             2       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HbnaQJxw2mHQ"
   },
   "source": [
    "В этом ноутбуке нам придётся подбирать гиперпараметры модели, а ещё порог. Поэтому, чтобы не переобучиться, разобъём данные на трейн, валидацию и тест.\n",
    "\n",
    "*  Обучать модели будем на тренировочных данных.\n",
    "*  Подбирать необходимые величины — по валидации.\n",
    "*  Оценивать качество — на тесте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "bkG1LjB0s81d"
   },
   "outputs": [],
   "source": [
    "# разделим данные на обучающую и тестовую выборки\n",
    "\n",
    "\n",
    "X = df.drop('TARGET', axis=1)\n",
    "y = df['TARGET']\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, train_size=0.7, random_state=123)\n",
    "Xtrain, Xval, ytrain, yval = train_test_split(Xtrain, ytrain, train_size=0.7, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9g3cyUKPqgqu"
   },
   "source": [
    "В задании по методу ближайших соседей было найдено, что оптимальное число соседей k = 9.\n",
    "\n",
    "Обучите на тренировочных данных KNN с k = 9 и выведите матрицу ошибок, а также значение метрик precision и recall на тестовых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "efySFKgej1_1"
   },
   "outputs": [],
   "source": [
    "knn_def = KNeighborsClassifier(n_neighbors=9)\n",
    "knn_def.fit(Xtrain, ytrain)\n",
    "knn_def_preds_test = knn_def.predict(Xtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_stats(true, preds):\n",
    "    print(confusion_matrix(true, preds))\n",
    "    print('----')\n",
    "    print(classification_report(true, preds))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3982   26]\n",
      " [ 553    6]]\n",
      "----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93      4008\n",
      "           1       0.19      0.01      0.02       559\n",
      "\n",
      "    accuracy                           0.87      4567\n",
      "   macro avg       0.53      0.50      0.48      4567\n",
      "weighted avg       0.79      0.87      0.82      4567\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_stats(ytest, knn_def_preds_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E9Bk7tSerX-L"
   },
   "source": [
    "Какой вывод можно сделать:\n",
    "- для класса 0 — клиент не откликнулся — мы получили достаточно высокие значения TP в том числе потому, что представителей этого класса больше;\n",
    "- для класса 1 — клиент откликнулся — мы получили низкие значения TN.\n",
    "\n",
    "Поэтому значения precision и recall низкие. Модель даёт неудовлетворительные результаты, так как находит мало клиентов, которые откликнутся на предложение.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zGmfshG9rmBn"
   },
   "source": [
    "Обучите логистическую регрессию с параметрами по умолчанию и посмотрите на метрики.\n",
    "\n",
    "Везде дальше при оценке метрик надо выводить confusion_matrix, precision и recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "7tOX78zbrPHB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4008    0]\n",
      " [ 559    0]]\n",
      "----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93      4008\n",
      "           1       0.00      0.00      0.00       559\n",
      "\n",
      "    accuracy                           0.88      4567\n",
      "   macro avg       0.44      0.50      0.47      4567\n",
      "weighted avg       0.77      0.88      0.82      4567\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ваш код здесь\n",
    "logr_def = LogisticRegression()\n",
    "logr_def.fit(Xtrain, ytrain)\n",
    "logr_def_preds_test = logr_def.predict(Xtest)\n",
    "show_stats(ytest, logr_def_preds_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CvWGh7m9sTKM"
   },
   "source": [
    "Наша цель — найти как можно больше клиентов, которые откликнутся на предложение. А модель таких не находит. \n",
    "\n",
    "Мы помним, что метод predict_proba у логистической регрессии предсказывает математические (то есть корректные) вероятности классов. Предскажите вероятности классов с помощью обученной логистической регрессии на тестовых данных и выведите вероятности положительного класса для первых десяти объектов. \n",
    "\n",
    "Глядя на полученные вероятности, попробуйте объяснить, почему вы получили именно такую матрицу ошибок и такие значения точности с полноты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "LNqjcxrwsLzl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14042412],\n",
       "       [0.14107445],\n",
       "       [0.19378158],\n",
       "       [0.27151564],\n",
       "       [0.12612216],\n",
       "       [0.04103151],\n",
       "       [0.04261878],\n",
       "       [0.03656178],\n",
       "       [0.08229851],\n",
       "       [0.06786435]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ваш код здесь\n",
    "logr_def_probs_test = logr_def.predict_proba(Xtest)\n",
    "logr_def_probs_test[:10,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "mwJzqbfv5yE4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11432928775728438\n"
     ]
    }
   ],
   "source": [
    "# ваше объяснение здесь\n",
    "# ремарка - я пишу это по второму кругу, по этому чуть более кратко, тем более, \n",
    "# что мои выводы, как выснилось, подтвердились в следующем модуле:)\n",
    "\n",
    "# 1) главная причина в несбалансированности данных\n",
    "# 2) едва ли дело в пороге - в среднем порог нужно будет опустить ну ооочень сильно, чтобы он как то влиял на реколл\n",
    "# т.к. вероятность 'единичек' уж совсем какая то небольшая.\n",
    "print(logr_def_probs_test[:10,1:].mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z08xmRAcugGb"
   },
   "source": [
    "Давайте уточним цель. Пусть нам нужно найти как можно больше клиентов, которые откликнутся на предложение, то есть максимизировать полноту (recall). \n",
    "\n",
    "При этом хочется, чтобы точность модели (precision) не была очень низкой. Заказчик посмотрел на результаты работы KNN и потребовал, чтобы точность была не ниже, чем у KNN: $precision \\geq 0.13$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-syFkflt6EV"
   },
   "source": [
    "Давайте будем изменять порог для перевода вероятности в классы так, чтобы:\n",
    "*   максимизировать значение recall\n",
    "*   при условии, что $precision \\geq 0.13$.\n",
    "\n",
    "Если мы будем подбирать порог по тестовой выборке, то, по сути, обучимся на ней и, значит, переобучимся. Это плохо. \n",
    "\n",
    "Поэтому предскажите вероятности на валидационной выборке и подберите порог по ней (Xval, yval), а затем посмотрите, какое качество для найденного порога вы получите на тестовых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "398pACpBtFi2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best thr appears to be   0.07300000000000004 \n",
      " ------\n"
     ]
    }
   ],
   "source": [
    "scores = dict()\n",
    "logr_def_probs_val = logr_def.predict_proba(Xval)# ваш код здесь\n",
    "\n",
    "max_recall = -1\n",
    "best_precision = -1\n",
    "best_thr = -1\n",
    "\n",
    "for threshold in np.arange(0.04, 1, 0.001):\n",
    "    \n",
    "    # для каждого значения порога переведите вероятности в классы\n",
    "    preds_tuned_thr_val = (logr_def_probs_val[:,1:] > threshold).astype(int)\n",
    "    \n",
    "    if precision_score(yval, preds_tuned_thr_val) >= 0.13:\n",
    "        # посчитайте метрики\n",
    "        scores[str(threshold)] = {\n",
    "            'recall': recall_score(yval, preds_tuned_thr_val),\n",
    "            'precision': precision_score(yval, preds_tuned_thr_val),\n",
    "            'thr': threshold,\n",
    "        }\n",
    "#     else:\n",
    "#         print('precision score ', precision_score(yval, preds_tuned_thr_val), 'thr is ', threshold)\n",
    "\n",
    "        \n",
    "for key in scores.keys():\n",
    "    if scores[key]['recall'] > max_recall:\n",
    "        max_recall = scores[key]['recall']\n",
    "        best_precision = scores[key]['precision']\n",
    "        best_thr = scores[key]['thr']\n",
    "print(\n",
    "    'best thr appears to be  ', best_thr,'\\n ------'\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "# напечатайте порог, для которого получается максимальная полнота, при precision >= 0.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "qpHv0DVwywKq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 380 3628]\n",
      " [  20  539]]\n",
      "----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.09      0.17      4008\n",
      "           1       0.13      0.96      0.23       559\n",
      "\n",
      "    accuracy                           0.20      4567\n",
      "   macro avg       0.54      0.53      0.20      4567\n",
      "weighted avg       0.85      0.20      0.18      4567\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# по найденному порогу переведите вероятности в классы на тесте и напечатайте метрики\n",
    "\n",
    "logr_def_probs_test = logr_def.predict_proba(Xtest)       \n",
    "preds_tuned_thr_test = (logr_def_probs_test[:,1:] >= best_thr).astype(int)#0.046).astype(int)\n",
    "\n",
    "show_stats(ytest, preds_tuned_thr_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fLakCD5TwmDe"
   },
   "source": [
    "Сделайте вывод. Смогли ли мы с помощью подбора порога добиться большего значения recall, чем у KNN? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3982   26]\n",
      " [ 553    6]]\n",
      "----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93      4008\n",
      "           1       0.19      0.01      0.02       559\n",
      "\n",
      "    accuracy                           0.87      4567\n",
      "   macro avg       0.53      0.50      0.48      4567\n",
      "weighted avg       0.79      0.87      0.82      4567\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_stats(ytest, knn_def_preds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "222ZBiDy6Z1_"
   },
   "outputs": [],
   "source": [
    "# ваш вывод здесь\n",
    "# однозначно! все как по правилу, так и по логике - меньше порог -> больше захватываем, как искомых положительных, так \n",
    "# и всего остального - FP, как видите - очень высок"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zc1D7Hy8wvkR"
   },
   "source": [
    "А ещё, чтобы улучшить качество предсказания, можно подбирать значение гиперпараметра C у логистической регрессии. Для каждого значения C придётся подбирать свой порог, поэтому:  \n",
    "\n",
    "1. Обучите для значений C из диапазона [0.05, 0.15, 0.25, ...., 10.05] логистическую регрессию (на тренировочных данных).\n",
    "\n",
    "2. Для каждой из обученных моделей во внутреннем цикле подберите оптимальный порог (как в предыдущем задании) — на валидационных данных.\n",
    "\n",
    "\n",
    "\n",
    "В качестве результата выведите значение C и порога для модели, которая даёт наилучшие значения метрик (наибольший recall при ограничении на $precision \\geq 0.13$).\n",
    "\n",
    "Также напечатайте полученные метрики (матрицу ошибок, точность и полноту) для лучшей модели — на тестовых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0028328611898017\n"
     ]
    }
   ],
   "source": [
    "scores = dict()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for current_reg in np.arange(0.01, 50.05, 0.5):#(0.05, 10.05, 0.05):\n",
    "    max_recall = -1\n",
    "    best_precision = -1\n",
    "    best_thr = -1\n",
    "\n",
    "    logr_tuned_c = LogisticRegression(C=current_reg)\n",
    "    logr_tuned_c.fit(Xtrain, ytrain)\n",
    "\n",
    "\n",
    "    logr_tuned_c_probs_val = logr_tuned_c.predict_proba(Xval)\n",
    "\n",
    "    scores_interm = dict()\n",
    "\n",
    "    for threshold in np.arange(0.04, 1, 0.001):#(0.04, 1, 0.001):\n",
    "\n",
    "        # для каждого значения порога переведите вероятности в классы\n",
    "        preds_tuned_thr_val = (logr_tuned_c_probs_val[:,1:] > threshold).astype(int)\n",
    "\n",
    "        if precision_score(yval, preds_tuned_thr_val) >= 0.13:\n",
    "            # посчитайте метрики\n",
    "            scores_interm[str(current_reg)] = {\n",
    "                'recall': recall_score(yval, preds_tuned_thr_val),\n",
    "                'precision': precision_score(yval, preds_tuned_thr_val),\n",
    "                'thr': threshold,\n",
    "            }\n",
    "    #     else:\n",
    "    #         print('precision score ', precision_score(yval, preds_tuned_thr_val), 'thr is ', threshold)\n",
    "\n",
    "\n",
    "    for key in scores_interm.keys():\n",
    "        if scores_interm[key]['recall'] > max_recall:\n",
    "            max_recall = scores_interm[key]['recall']\n",
    "            best_precision = scores_interm[key]['precision']\n",
    "            best_thr = scores_interm[key]['thr']\n",
    "\n",
    "    scores[str(current_reg)] = {\n",
    "                'recall': max_recall,\n",
    "                'precision': best_precision,\n",
    "                'thr': best_thr,\n",
    "                'best_C': current_reg,\n",
    "            }\n",
    "\n",
    "\n",
    "max_recall = -1\n",
    "\n",
    "        \n",
    "for key in scores.keys():\n",
    "    if scores[key]['recall'] > max_recall:\n",
    "        max_recall = scores[key]['recall']\n",
    "print(max_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0.05': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 0.05},\n",
       " '0.1': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 0.1},\n",
       " '0.15000000000000002': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 0.15000000000000002},\n",
       " '0.2': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 0.2},\n",
       " '0.25': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 0.25},\n",
       " '0.3': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 0.3},\n",
       " '0.35000000000000003': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 0.35000000000000003},\n",
       " '0.4': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 0.4},\n",
       " '0.45': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 0.45},\n",
       " '0.5': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 0.5},\n",
       " '0.55': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 0.55},\n",
       " '0.6000000000000001': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 0.6000000000000001},\n",
       " '0.6500000000000001': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 0.6500000000000001},\n",
       " '0.7000000000000001': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 0.7000000000000001},\n",
       " '0.7500000000000001': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 0.7500000000000001},\n",
       " '0.8': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 0.8},\n",
       " '0.8500000000000001': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 0.8500000000000001},\n",
       " '0.9000000000000001': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 0.9000000000000001},\n",
       " '0.9500000000000001': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 0.9500000000000001},\n",
       " '1.0': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 1.0},\n",
       " '1.05': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 1.05},\n",
       " '1.1': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 1.1},\n",
       " '1.1500000000000001': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 1.1500000000000001},\n",
       " '1.2000000000000002': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 1.2000000000000002},\n",
       " '1.2500000000000002': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 1.2500000000000002},\n",
       " '1.3': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 1.3},\n",
       " '1.35': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 1.35},\n",
       " '1.4000000000000001': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 1.4000000000000001},\n",
       " '1.4500000000000002': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 1.4500000000000002},\n",
       " '1.5000000000000002': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 1.5000000000000002},\n",
       " '1.55': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 1.55},\n",
       " '1.6': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 1.6},\n",
       " '1.6500000000000001': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 1.6500000000000001},\n",
       " '1.7000000000000002': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 1.7000000000000002},\n",
       " '1.7500000000000002': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 1.7500000000000002},\n",
       " '1.8': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 1.8},\n",
       " '1.85': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 1.85},\n",
       " '1.9000000000000001': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 1.9000000000000001},\n",
       " '1.9500000000000002': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 1.9500000000000002},\n",
       " '2.0': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 2.0},\n",
       " '2.05': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 2.05},\n",
       " '2.1': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 2.1},\n",
       " '2.15': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 2.15},\n",
       " '2.1999999999999997': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 2.1999999999999997},\n",
       " '2.25': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 2.25},\n",
       " '2.3': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 2.3},\n",
       " '2.35': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 2.35},\n",
       " '2.4': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 2.4},\n",
       " '2.45': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 2.45},\n",
       " '2.5': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 2.5},\n",
       " '2.55': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 2.55},\n",
       " '2.6': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 2.6},\n",
       " '2.65': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 2.65},\n",
       " '2.7': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 2.7},\n",
       " '2.75': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 2.75},\n",
       " '2.8': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 2.8},\n",
       " '2.85': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 2.85},\n",
       " '2.9': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 2.9},\n",
       " '2.95': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 2.95},\n",
       " '3.0': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 3.0},\n",
       " '3.05': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 3.05},\n",
       " '3.1': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 3.1},\n",
       " '3.15': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 3.15},\n",
       " '3.2': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 3.2},\n",
       " '3.25': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 3.25},\n",
       " '3.3': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 3.3},\n",
       " '3.35': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 3.35},\n",
       " '3.4': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 3.4},\n",
       " '3.45': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 3.45},\n",
       " '3.5': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 3.5},\n",
       " '3.55': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 3.55},\n",
       " '3.6': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 3.6},\n",
       " '3.65': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 3.65},\n",
       " '3.7': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 3.7},\n",
       " '3.75': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 3.75},\n",
       " '3.8': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 3.8},\n",
       " '3.85': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 3.85},\n",
       " '3.9': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 3.9},\n",
       " '3.95': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 3.95},\n",
       " '4.0': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 4.0},\n",
       " '4.05': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 4.05},\n",
       " '4.1': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 4.1},\n",
       " '4.15': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 4.15},\n",
       " '4.2': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 4.2},\n",
       " '4.25': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 4.25},\n",
       " '4.3': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 4.3},\n",
       " '4.35': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 4.35},\n",
       " '4.4': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 4.4},\n",
       " '4.45': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 4.45},\n",
       " '4.5': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 4.5},\n",
       " '4.55': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 4.55},\n",
       " '4.6': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 4.6},\n",
       " '4.65': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 4.65},\n",
       " '4.7': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 4.7},\n",
       " '4.75': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 4.75},\n",
       " '4.8': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 4.8},\n",
       " '4.8500000000000005': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 4.8500000000000005},\n",
       " '4.9': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 4.9},\n",
       " '4.95': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 4.95},\n",
       " '5.0': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 5.0},\n",
       " '5.05': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 5.05},\n",
       " '5.1000000000000005': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 5.1000000000000005},\n",
       " '5.15': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 5.15},\n",
       " '5.2': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 5.2},\n",
       " '5.25': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 5.25},\n",
       " '5.3': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 5.3},\n",
       " '5.3500000000000005': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 5.3500000000000005},\n",
       " '5.4': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 5.4},\n",
       " '5.45': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 5.45},\n",
       " '5.5': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 5.5},\n",
       " '5.55': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 5.55},\n",
       " '5.6000000000000005': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 5.6000000000000005},\n",
       " '5.65': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 5.65},\n",
       " '5.7': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 5.7},\n",
       " '5.75': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 5.75},\n",
       " '5.8': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 5.8},\n",
       " '5.8500000000000005': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 5.8500000000000005},\n",
       " '5.9': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 5.9},\n",
       " '5.95': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 5.95},\n",
       " '6.0': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 6.0},\n",
       " '6.05': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 6.05},\n",
       " '6.1000000000000005': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 6.1000000000000005},\n",
       " '6.15': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 6.15},\n",
       " '6.2': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 6.2},\n",
       " '6.25': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 6.25},\n",
       " '6.3': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 6.3},\n",
       " '6.3500000000000005': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 6.3500000000000005},\n",
       " '6.4': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 6.4},\n",
       " '6.45': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 6.45},\n",
       " '6.5': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 6.5},\n",
       " '6.55': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 6.55},\n",
       " '6.6000000000000005': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 6.6000000000000005},\n",
       " '6.65': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 6.65},\n",
       " '6.7': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 6.7},\n",
       " '6.75': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 6.75},\n",
       " '6.8': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 6.8},\n",
       " '6.8500000000000005': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 6.8500000000000005},\n",
       " '6.9': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 6.9},\n",
       " '6.95': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 6.95},\n",
       " '7.0': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 7.0},\n",
       " '7.05': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 7.05},\n",
       " '7.1000000000000005': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 7.1000000000000005},\n",
       " '7.15': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 7.15},\n",
       " '7.2': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 7.2},\n",
       " '7.25': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 7.25},\n",
       " '7.3': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 7.3},\n",
       " '7.3500000000000005': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 7.3500000000000005},\n",
       " '7.4': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 7.4},\n",
       " '7.45': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 7.45},\n",
       " '7.5': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 7.5},\n",
       " '7.55': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 7.55},\n",
       " '7.6000000000000005': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 7.6000000000000005},\n",
       " '7.65': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 7.65},\n",
       " '7.7': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 7.7},\n",
       " '7.75': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 7.75},\n",
       " '7.8': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 7.8},\n",
       " '7.8500000000000005': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 7.8500000000000005},\n",
       " '7.9': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 7.9},\n",
       " '7.95': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 7.95},\n",
       " '8.0': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 8.0},\n",
       " '8.05': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 8.05},\n",
       " '8.100000000000001': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 8.100000000000001},\n",
       " '8.15': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 8.15},\n",
       " '8.200000000000001': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 8.200000000000001},\n",
       " '8.250000000000002': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 8.250000000000002},\n",
       " '8.3': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 8.3},\n",
       " '8.350000000000001': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 8.350000000000001},\n",
       " '8.4': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 8.4},\n",
       " '8.450000000000001': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 8.450000000000001},\n",
       " '8.500000000000002': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 8.500000000000002},\n",
       " '8.55': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 8.55},\n",
       " '8.600000000000001': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 8.600000000000001},\n",
       " '8.65': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 8.65},\n",
       " '8.700000000000001': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 8.700000000000001},\n",
       " '8.750000000000002': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 8.750000000000002},\n",
       " '8.8': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 8.8},\n",
       " '8.850000000000001': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 8.850000000000001},\n",
       " '8.9': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 8.9},\n",
       " '8.950000000000001': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 8.950000000000001},\n",
       " '9.000000000000002': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 9.000000000000002},\n",
       " '9.05': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 9.05},\n",
       " '9.100000000000001': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 9.100000000000001},\n",
       " '9.15': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 9.15},\n",
       " '9.200000000000001': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 9.200000000000001},\n",
       " '9.250000000000002': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 9.250000000000002},\n",
       " '9.3': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 9.3},\n",
       " '9.350000000000001': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 9.350000000000001},\n",
       " '9.4': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 9.4},\n",
       " '9.450000000000001': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 9.450000000000001},\n",
       " '9.500000000000002': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 9.500000000000002},\n",
       " '9.55': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 9.55},\n",
       " '9.600000000000001': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 9.600000000000001},\n",
       " '9.650000000000002': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 9.650000000000002},\n",
       " '9.700000000000001': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 9.700000000000001},\n",
       " '9.750000000000002': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 9.750000000000002},\n",
       " '9.8': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 9.8},\n",
       " '9.850000000000001': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 9.850000000000001},\n",
       " '9.900000000000002': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 9.900000000000002},\n",
       " '9.950000000000001': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 9.950000000000001},\n",
       " '10.000000000000002': {'recall': 0.0028328611898017,\n",
       "  'precision': 0.25,\n",
       "  'thr': 0.32600000000000023,\n",
       "  'best_C': 10.000000000000002}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EhjmTEkhuT9S"
   },
   "outputs": [],
   "source": [
    "regs = []\n",
    "recalls = []\n",
    "thresholds = []\n",
    "precisions = []\n",
    "\n",
    "for reg in np.arange(0.001, 1, 0.01):\n",
    "\n",
    "    # обучите логистическую регрессию с C=reg\n",
    "\n",
    "    max_recall = -1\n",
    "    thr = -1\n",
    "    prec = -1\n",
    "\n",
    "    for threshold in np.arange(0.05, 0.25, 0.001):\n",
    "        # подберите оптимальный порог как в задании выше\n",
    "\n",
    "    recalls.append(max_recall)\n",
    "    thresholds.append(thr)\n",
    "    precisions.append(prec)\n",
    "    regs.append(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DZtXAIxi0Ksr"
   },
   "outputs": [],
   "source": [
    "# выведите значения C, precision, recall, threshold для наилучшей по заданным условиям модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rQLQZ1bg4BGy"
   },
   "outputs": [],
   "source": [
    "# с помощью найденных C и threshold обучите модель на тренировочных данных, сделайте предсказание на тесте и по найденному порогу получите классы\n",
    "# напечатайте метрики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fwpx_UVS2DK_"
   },
   "source": [
    "Влияет ли изменение гиперпараметра C на качество модели (и, соответственно, метрики) в этой задаче?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FzTsUr7p7Eu-"
   },
   "outputs": [],
   "source": [
    "# ваш вывод здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BaCqlDx74pns"
   },
   "source": [
    "Ответьте развёрнуто на следующие вопросы:\n",
    "\n",
    "* Удалось ли при помощи логистической регрессии и подбора порога превзойти качество метода ближайших соседей в этой задаче? \n",
    "\n",
    "* Смогли ли мы при помощи этой модели получить высокий recall при ограничениях, поставленных заказчиком?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upznWo7n4o0F"
   },
   "outputs": [],
   "source": [
    "# ваш вывод здесь"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
